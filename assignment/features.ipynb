{
 "metadata": {
  "name": "",
  "signature": "sha256:52776c9bf9c364fc0abd72295e13648a1f554df5546eddb3bbfb87800bebff43"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Plankton Dataset\n",
      "In Part 1) we will train best CNN  for plankton dataset.\n",
      "In Part 2) we will use featues from our CNN combined with features got from running the alexnet, bvlcc net on images and train linear classifier on top of it.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A bit of setup\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from time import time\n",
      "\n",
      "%matplotlib inline\n",
      "plt.rcParams['figure.figsize'] = (20.0, 20.0) # set default size of plots\n",
      "plt.rcParams['image.interpolation'] = 'nearest'\n",
      "plt.rcParams['image.cmap'] = 'gray'\n",
      "\n",
      "# for auto-reloading extenrnal modules\n",
      "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the model above to get probabilities for each class on test dataset.\n",
      "Run it in batches to avoid crash of ipython\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load features from files\n",
      "X_train_feats7 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/7layer_features/X_train_7layer_conv_features.npy')\n",
      "X_val1_feats7 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/7layer_features/X_valid1_7layer_conv_features.npy')\n",
      "X_val2_feats7 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/7layer_features/X_valid2_7layer_conv_features.npy')\n",
      "X_test_feats7 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/7layer_features/X_test_7layer_conv_features.npy')\n",
      "y_train = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/y_train.npy')\n",
      "y_val1 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/y_valid1.npy')\n",
      "y_val2 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/y_valid2.npy')\n",
      "#image_index = np.load('/Users/sagarc/Documents/cs231n/project/plankton/5layer_features/5layer_image_index.npy')\n",
      "#image_mapping = np.load('/Users/sagarc/Documents/cs231n/project/plankton/5layer_features/5layer_image_mapping.npy')\n",
      "print X_train_feats7.shape, X_val1_feats7.shape, X_val2_feats7.shape, X_test_feats7.shape, y_train.shape, y_val1.shape, y_val2.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(28336, 128) (1000, 128) (1000, 128) (130400, 128) (28336,) (1000,) (1000,)\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load features from files\n",
      "X_train_feats5 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/5layer_features/X_train_5layer_conv_features.npy')\n",
      "X_val1_feats5 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/5layer_features/X_valid1_5layer_conv_features.npy')\n",
      "X_val2_feats5 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/5layer_features/X_valid2_5layer_conv_features.npy')\n",
      "X_test_feats5 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/5layer_features/X_test_5layer_conv_features.npy')\n",
      "y_train = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/y_train.npy')\n",
      "y_val1 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/y_valid1.npy')\n",
      "y_val2 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/y_valid2.npy')\n",
      "#image_index = np.load('/Users/sagarc/Documents/cs231n/project/plankton/5layer_features/5layer_image_index.npy')\n",
      "#image_mapping = np.load('/Users/sagarc/Documents/cs231n/project/plankton/5layer_features/5layer_image_mapping.npy')\n",
      "print X_train_feats5.shape, X_val1_feats5.shape, X_val2_feats5.shape, X_test_feats5.shape, y_train.shape, y_val1.shape, y_val2.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(28336, 128) (1000, 128) (1000, 128) (130400, 128) (28336,) (1000,) (1000,)\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load features from files for 3 layer\n",
      "X_train_feats3 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/3layer_features/X_train_3layer_conv_features.npy')\n",
      "X_val1_feats3 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/3layer_features/X_valid1_3layer_conv_features.npy')\n",
      "X_val2_feats3 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/3layer_features/X_valid2_3layer_conv_features.npy')\n",
      "X_test_feats3 = np.load('/Users/sagarc/Documents/cs231n/project/plankton/3layer_features/X_test_3layer_conv_features.npy')\n",
      "\n",
      "print X_train_feats3.shape, X_val1_feats3.shape, X_val2_feats3.shape, X_test_feats3.shape, y_train.shape, y_val1.shape, y_val2.shape\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(28336, 128) (1000, 128) (1000, 128) (130400, 128) (28336,) (1000,) (1000,)\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cs231n.features import *\n",
      "\n",
      "# Extract features. For each image we will compute a Histogram of Oriented\n",
      "# Gradients (HOG) as well as a color histogram using the hue channel in HSV\n",
      "# color space. We form our final feature vector for each image by concatenating\n",
      "# the HOG and color histogram feature vectors.\n",
      "#\n",
      "# Roughly speaking, HOG should capture the texture of the image while ignoring\n",
      "# color information, and the color histogram represents the color of the input\n",
      "# image while ignoring texture. As a result, we expect that using both together\n",
      "# ought to work better than using either alone. Verifying this assumption would\n",
      "# be a good thing to try for the bonus section.\n",
      "\n",
      "# The hog_feature and color_histogram_hsv functions both operate on a single\n",
      "# image and return a feature vector for that image. The extract_features\n",
      "# function takes a set of images and a list of feature functions and evaluates\n",
      "# each feature function on each image, storing the results in a matrix where\n",
      "# each column is the concatenation of all feature vectors for a single image.\n",
      "\n",
      "num_color_bins = 10 # Number of bins in the color histogram\n",
      "feature_fns = [hog_feature]\n",
      "X_train_feats = extract_features(X_train, feature_fns, verbose=True)\n",
      "X_val_feats = extract_features(X_val, feature_fns)\n",
      "X_test_feats = extract_features(X_test, feature_fns)\n",
      "\n",
      "# Preprocessing: Subtract the mean feature\n",
      "mean_feat = np.mean(X_train_feats, axis=1)\n",
      "mean_feat = np.expand_dims(mean_feat, axis=1)\n",
      "X_train_feats -= mean_feat\n",
      "X_val_feats -= mean_feat\n",
      "X_test_feats -= mean_feat\n",
      "\n",
      "# Preprocessing: Divide by standard deviation. This ensures that each feature\n",
      "# has roughly the same scale.\n",
      "std_feat = np.std(X_train_feats, axis=1)\n",
      "std_feat = np.expand_dims(std_feat, axis=1)\n",
      "X_train_feats /= std_feat\n",
      "X_val_feats /= std_feat\n",
      "X_test_feats /= std_feat\n",
      "\n",
      "# Preprocessing: Add a bias dimension\n",
      "X_train_feats = np.vstack([X_train_feats, np.ones((1, X_train_feats.shape[1]))])\n",
      "X_val_feats = np.vstack([X_val_feats, np.ones((1, X_val_feats.shape[1]))])\n",
      "X_test_feats = np.vstack([X_test_feats, np.ones((1, X_test_feats.shape[1]))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Try out model ensemble of various linear layers\n",
      "\n",
      "from cs231n.classifiers.linear_classifier import Softmax\n",
      "\n",
      "softmax_y_train_pred = None\n",
      "softmax_y_val_pred = None\n",
      "\n",
      "lr_list = [1e-3, 1e-4]\n",
      "reg_list = [1e-4, 1e-5, 2e-6]\n",
      "best_val_acc = 0\n",
      "best_train_acc = 0\n",
      "best_lr = 0\n",
      "best_reg = 0\n",
      "best_loss = 5\n",
      "best_softmax = []\n",
      "#ensemble of 5 models\n",
      "for i in xrange(0,2):\n",
      "    for lr in lr_list:\n",
      "        for reg in reg_list:\n",
      "            softmax = Softmax()\n",
      "            y_train.astype(int)\n",
      "            loss_history = softmax.train(X_train_feats3.T, y_train, verbose=True, learning_rate=lr, reg=reg, num_iters=10000)\n",
      "            softmax_y_train_pred = softmax.predict(X_train_feats3.T)\n",
      "\n",
      "            softmax_y_val_pred = softmax.predict(X_val1_feats3.T)\n",
      "            train_acc = np.mean(y_train == softmax_y_train_pred)\n",
      "            val_acc = np.mean(softmax_y_val_pred == y_val1)\n",
      "            loss, dW = softmax.loss(X_val1_feats5.T, y_val1, reg)\n",
      "            print \"lr {} reg {} train_acc {} val_acc {} loss{}\".format(lr,reg,train_acc,val_acc, loss)\n",
      "            if loss < best_loss:\n",
      "                best_train_acc = train_acc\n",
      "                best_val_acc = val_acc\n",
      "                best_lr = lr\n",
      "                best_reg = reg\n",
      "                best_loss = loss\n",
      "    best_softmax.append(softmax)\n",
      "\"\"\"\n",
      "Using features from 5 layer and 7 layer convnet together, Accuracy is not improved that lot\n",
      "(121, 256)\n",
      "lr 0.001 reg 0.2 train_acc 0.711109542631 val_acc 0.574 loss2.56336768381\n",
      "(121, 256)\n",
      "lr 0.001 reg 0.5 train_acc 0.668619424054 val_acc 0.56 loss2.9604700634\n",
      "(121, 256)\n",
      "lr 0.002 reg 0.2 train_acc 0.712097684924 val_acc 0.574 loss2.56692026737\n",
      "(121, 256)\n",
      "lr 0.002 reg 0.5 train_acc 0.672077922078 val_acc 0.559 loss2.96901989098\n",
      "\"\"\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.800951\n",
        "iteration 5000 / 10000: loss 1.122304"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 0.0001 train_acc 0.665302089215 val_acc 0.587 loss5.04690011076"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.787662\n",
        "iteration 5000 / 10000: loss 1.230638"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 1e-05 train_acc 0.666960756635 val_acc 0.574 loss5.05157552012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.799303\n",
        "iteration 5000 / 10000: loss 1.262621"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 2e-06 train_acc 0.667313664596 val_acc 0.573 loss5.05031021211"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.805384\n",
        "iteration 5000 / 10000: loss 1.885101"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.0001 reg 0.0001 train_acc 0.581980519481 val_acc 0.544 loss4.65247586641"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.796965\n",
        "iteration 5000 / 10000: loss 1.868883"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.0001 reg 1e-05 train_acc 0.583003952569 val_acc 0.543 loss4.6456822645"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.794424\n",
        "iteration 5000 / 10000: loss 1.892710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.0001 reg 2e-06 train_acc 0.582192264257 val_acc 0.54 loss4.6524256403"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.821506\n",
        "iteration 5000 / 10000: loss 1.182355"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 0.0001 train_acc 0.66406691135 val_acc 0.58 loss5.0466995155"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.795952\n",
        "iteration 5000 / 10000: loss 1.229888"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 1e-05 train_acc 0.665019762846 val_acc 0.586 loss5.0480944573"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.808101\n",
        "iteration 5000 / 10000: loss 1.363376"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 2e-06 train_acc 0.665584415584 val_acc 0.571 loss5.04545592228"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.789461\n",
        "iteration 5000 / 10000: loss 1.771955"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.0001 reg 0.0001 train_acc 0.582827498588 val_acc 0.542 loss4.65096550241"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.800402\n",
        "iteration 5000 / 10000: loss 2.051895"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.0001 reg 1e-05 train_acc 0.581592320723 val_acc 0.539 loss4.64733706075"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 128)\n",
        "iteration 0 / 10000: loss 4.808148\n",
        "iteration 5000 / 10000: loss 2.073683"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.0001 reg 2e-06 train_acc 0.582333427442 val_acc 0.541 loss4.65375416575"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 111,
       "text": [
        "'\\nUsing features from 5 layer and 7 layer convnet together, Accuracy is not improved that lot\\n(121, 256)\\nlr 0.001 reg 0.2 train_acc 0.711109542631 val_acc 0.574 loss2.56336768381\\n(121, 256)\\nlr 0.001 reg 0.5 train_acc 0.668619424054 val_acc 0.56 loss2.9604700634\\n(121, 256)\\nlr 0.002 reg 0.2 train_acc 0.712097684924 val_acc 0.574 loss2.56692026737\\n(121, 256)\\nlr 0.002 reg 0.5 train_acc 0.672077922078 val_acc 0.559 loss2.96901989098\\n'"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Consolidate the features\n",
      "num_train_samples = X_train_feats5.shape[0]\n",
      "num_features = X_train_feats5.shape[1]\n",
      "X_train_feats_consolidated = np.zeros([num_train_samples, num_features * 2])\n",
      "X_train_feats_consolidated[:,0:num_features] = X_train_feats5\n",
      "X_train_feats_consolidated[:,num_features:2*num_features] = X_train_feats7\n",
      "#X_train_feats_consolidated[:,2*num_features:] = X_train_feats3\n",
      "print X_train_feats_consolidated.shape\n",
      "\n",
      "num_valid_samples = X_val1_feats5.shape[0]\n",
      "X_val1_feats_consolidated = np.zeros([num_valid_samples, num_features * 2])\n",
      "X_val1_feats_consolidated[:,0:num_features] = X_val1_feats5\n",
      "X_val1_feats_consolidated[:,num_features:2*num_features] = X_val1_feats7\n",
      "#X_val1_feats_consolidated[:,2*num_features:] = X_val1_feats3\n",
      "print X_val1_feats_consolidated.shape\n",
      "\n",
      "num_test_samples = X_test_feats5.shape[0]\n",
      "num_features = X_train_feats5.shape[1]\n",
      "X_test_feats_consolidated = np.zeros([num_test_samples, num_features * 2])\n",
      "X_test_feats_consolidated[:,0:num_features] = X_test_feats5\n",
      "X_test_feats_consolidated[:,num_features:2*num_features] = X_test_feats7\n",
      "#X_test_feats_consolidated[:,2*num_features:] = X_test_feats3\n",
      "print X_test_feats_consolidated.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(28336, 256)\n",
        "(1000, 256)\n",
        "(130400, 256)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fine-tuning\n",
      "use features coming from bvlc_reference and improve the performance of model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Try out model ensemble of various linear layers\n",
      "\n",
      "from cs231n.classifiers.linear_classifier import Softmax\n",
      "\n",
      "softmax_y_train_pred = None\n",
      "softmax_y_val_pred = None\n",
      "\n",
      "lr_list = [1e-3]\n",
      "reg_list = [1e-4]\n",
      "best_val_acc = 0\n",
      "best_train_acc = 0\n",
      "best_lr = 0\n",
      "best_reg = 0\n",
      "\n",
      "best_softmax = []\n",
      "#ensemble of 5 models\n",
      "for i in xrange(0,5):\n",
      "    best_loss = 5\n",
      "    for lr in lr_list:\n",
      "        for reg in reg_list:\n",
      "            softmax = Softmax()\n",
      "            y_train.astype(int)\n",
      "            loss_history = softmax.train(X_train_feats_consolidated.T, y_train, verbose=True, learning_rate=lr, reg=reg, num_iters=40000)\n",
      "            softmax_y_train_pred = softmax.predict(X_train_feats_consolidated.T)\n",
      "\n",
      "            softmax_y_val_pred = softmax.predict(X_val1_feats_consolidated.T)\n",
      "            train_acc = np.mean(y_train == softmax_y_train_pred)\n",
      "            val_acc = np.mean(softmax_y_val_pred == y_val1)\n",
      "            loss, dW = softmax.loss(X_val1_feats_consolidated.T, y_val1, reg)\n",
      "            print \"lr {} reg {} train_acc {} val_acc {} loss{}\".format(lr,reg,train_acc,val_acc, loss)\n",
      "            if loss < best_loss:\n",
      "                best_train_acc = train_acc\n",
      "                best_val_acc = val_acc\n",
      "                best_lr = lr\n",
      "                best_reg = reg\n",
      "                best_loss = loss\n",
      "                best_softmax.append(softmax)\n",
      "print len(best_softmax)\n",
      "\"\"\"\n",
      "3 , 5, 7 layers together:\n",
      "lr 0.001 reg 0.0001 train_acc 0.850225861095 val_acc 0.671 loss1.2361214135\n",
      "lr 0.001 reg 0.0001 train_acc 0.851849237719 val_acc 0.672 loss1.22984943641\n",
      "lr 0.001 reg 0.0001 train_acc 0.852166854884 val_acc 0.661 loss1.23054427647\n",
      "lr 0.001 reg 0.0001 train_acc 0.852872670807 val_acc 0.675 loss1.22939281006\n",
      "\"\"\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(121, 256)\n",
        "iteration 0 / 40000: loss 4.789220\n",
        "iteration 5000 / 40000: loss 0.833341"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 10000 / 40000: loss 0.773010"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 15000 / 40000: loss 0.641371"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 20000 / 40000: loss 0.700534"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 25000 / 40000: loss 0.876235"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 30000 / 40000: loss 0.694513"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 35000 / 40000: loss 0.706842"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 0.0001 train_acc 0.806818181818 val_acc 0.679 loss1.16034811473"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 256)\n",
        "iteration 0 / 40000: loss 4.799077\n",
        "iteration 5000 / 40000: loss 0.868325"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 10000 / 40000: loss 0.868458"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 15000 / 40000: loss 0.780429"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 20000 / 40000: loss 0.592161"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 25000 / 40000: loss 0.760352"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 30000 / 40000: loss 0.527063"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 35000 / 40000: loss 0.593738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 0.0001 train_acc 0.807135798984 val_acc 0.681 loss1.16385139511"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 256)\n",
        "iteration 0 / 40000: loss 4.800808\n",
        "iteration 5000 / 40000: loss 0.835702"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 10000 / 40000: loss 0.860656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 15000 / 40000: loss 0.599944"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 20000 / 40000: loss 0.736868"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 25000 / 40000: loss 0.642442"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 30000 / 40000: loss 0.699772"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 35000 / 40000: loss 0.522423"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 0.0001 train_acc 0.806782891022 val_acc 0.675 loss1.16215290268"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 256)\n",
        "iteration 0 / 40000: loss 4.792326\n",
        "iteration 5000 / 40000: loss 0.973924"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 10000 / 40000: loss 0.815335"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 15000 / 40000: loss 0.589629"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 20000 / 40000: loss 0.652654"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 25000 / 40000: loss 0.796092"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 30000 / 40000: loss 0.730905"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 35000 / 40000: loss 0.659150"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 0.0001 train_acc 0.807382834557 val_acc 0.68 loss1.16037338765"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(121, 256)\n",
        "iteration 0 / 40000: loss 4.795542\n",
        "iteration 5000 / 40000: loss 1.063749"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 10000 / 40000: loss 1.080802"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 15000 / 40000: loss 0.615648"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 20000 / 40000: loss 0.778106"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 25000 / 40000: loss 0.566186"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 30000 / 40000: loss 0.718853"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "iteration 35000 / 40000: loss 0.675505"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "lr 0.001 reg 0.0001 train_acc 0.806924054207 val_acc 0.682 loss1.15996600841"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 121,
       "text": [
        "'\\n3 , 5, 7 layers together:\\nlr 0.001 reg 0.0001 train_acc 0.850225861095 val_acc 0.671 loss1.2361214135\\nlr 0.001 reg 0.0001 train_acc 0.851849237719 val_acc 0.672 loss1.22984943641\\nlr 0.001 reg 0.0001 train_acc 0.852166854884 val_acc 0.661 loss1.23054427647\\nlr 0.001 reg 0.0001 train_acc 0.852872670807 val_acc 0.675 loss1.22939281006\\n'"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print best_softmax[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<cs231n.classifiers.linear_classifier.Softmax instance at 0x110217998>\n"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get average predictions now\n",
      "y_train_prob = np.zeros([121, X_train_feats.shape[0]])\n",
      "y_valid_prob = np.zeros([121,X_val1_feats.shape[0]])\n",
      "\n",
      "for model in best_softmax:\n",
      "    y_train_prob += model.predict(X_train_feats.T, get_prob=True)\n",
      "    y_valid_prob += model.predict(X_val2_feats.T,  get_prob=True)\n",
      "y_train_classes = np.argmax(y_train_prob, axis = 0)\n",
      "y_val_calsses = np.argmax(y_valid_prob, axis = 0)\n",
      "val_acc = np.mean(y_val_calsses == y_val2)\n",
      "train_acc = np.mean(y_train == y_train_classes)\n",
      "print \"val_acc {} train acc: {}\".format(val_acc, train_acc)\n",
      "    \n",
      "#print best_val_acc, best_train_acc, best_lr, best_reg, best_loss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "val_acc 0.633 train acc: 0.80459486166\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the scores for test dataset based on the best_softmax models ensemble\n",
      "\n",
      "f = open('test_probs_softmax_5_7layers.csv', 'w')\n",
      "class_names = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/class_names.npy')\n",
      "img_files = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/img_files.npy')\n",
      "class_labels = \",\".join(class_names)\n",
      "class_labels = \"image,\" + class_labels\n",
      "f.write(class_labels + \"\\n\")\n",
      "\n",
      "chunk_size = 1000\n",
      "num_test_samples = X_test_feats_consolidated.shape[0]\n",
      "for index_start in np.arange(0, num_test_samples, chunk_size):\n",
      "    y_test_prob = best_softmax[0].predict(X_test_feats_consolidated[index_start:np.minimum(index_start+chunk_size, \n",
      "                                                                                 num_test_samples)].T, \n",
      "                          get_prob=True)\n",
      "    y_test_prob = y_test_prob.T\n",
      "    \n",
      "    for i in xrange(y_test_prob.shape[0]):\n",
      "        prob_string = [\"%.8f\" % number for number in y_test_prob[i]]\n",
      "        f.write(img_files[index_start + i] + \",\" + \",\".join(prob_string) + \"\\n\")\n",
      "    print \"Processed test images from {} to {}\".format(index_start,  min(index_start + chunk_size, num_test_samples))\n",
      "f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processed test images from 0 to 1000\n",
        "Processed test images from 1000 to 2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 2000 to 3000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 3000 to 4000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 4000 to 5000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 5000 to 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 6000 to 7000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 7000 to 8000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 8000 to 9000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 9000 to 10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 10000 to 11000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 11000 to 12000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 12000 to 13000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 13000 to 14000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 14000 to 15000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 15000 to 16000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 16000 to 17000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 17000 to 18000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 18000 to 19000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 19000 to 20000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 20000 to 21000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 21000 to 22000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 22000 to 23000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 23000 to 24000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 24000 to 25000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 25000 to 26000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 26000 to 27000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 27000 to 28000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 28000 to 29000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 29000 to 30000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 30000 to 31000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 31000 to 32000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 32000 to 33000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 33000 to 34000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 34000 to 35000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 35000 to 36000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 36000 to 37000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 37000 to 38000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 38000 to 39000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 39000 to 40000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 40000 to 41000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 41000 to 42000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 42000 to 43000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 43000 to 44000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 44000 to 45000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 45000 to 46000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 46000 to 47000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 47000 to 48000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 48000 to 49000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 49000 to 50000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 50000 to 51000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 51000 to 52000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 52000 to 53000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 53000 to 54000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 54000 to 55000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 55000 to 56000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 56000 to 57000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 57000 to 58000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 58000 to 59000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 59000 to 60000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 60000 to 61000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 61000 to 62000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 62000 to 63000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 63000 to 64000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 64000 to 65000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 65000 to 66000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 66000 to 67000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 67000 to 68000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 68000 to 69000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 69000 to 70000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 70000 to 71000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 71000 to 72000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 72000 to 73000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 73000 to 74000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 74000 to 75000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 75000 to 76000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 76000 to 77000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 77000 to 78000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 78000 to 79000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 79000 to 80000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 80000 to 81000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 81000 to 82000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 82000 to 83000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 83000 to 84000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 84000 to 85000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 85000 to 86000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 86000 to 87000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 87000 to 88000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 88000 to 89000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 89000 to 90000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 90000 to 91000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 91000 to 92000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 92000 to 93000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 93000 to 94000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 94000 to 95000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 95000 to 96000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 96000 to 97000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 97000 to 98000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 98000 to 99000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 99000 to 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 100000 to 101000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 101000 to 102000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 102000 to 103000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 103000 to 104000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 104000 to 105000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 105000 to 106000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 106000 to 107000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 107000 to 108000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 108000 to 109000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 109000 to 110000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 110000 to 111000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 111000 to 112000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 112000 to 113000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 113000 to 114000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 114000 to 115000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 115000 to 116000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 116000 to 117000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 117000 to 118000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 118000 to 119000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 119000 to 120000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 120000 to 121000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 121000 to 122000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 122000 to 123000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 123000 to 124000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 124000 to 125000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 125000 to 126000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 126000 to 127000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 127000 to 128000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 128000 to 129000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 129000 to 130000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 130000 to 130400\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the scores for test dataset based on the best_softmax models ensemble\n",
      "\n",
      "f = open('test_probs_softmax_5_7layers_ensemble.csv', 'w')\n",
      "class_names = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/class_names.npy')\n",
      "img_files = np.load('/Users/sagarc/Documents/cs231n/project/plankton/y_labels/img_files.npy')\n",
      "class_labels = \",\".join(class_names)\n",
      "class_labels = \"image,\" + class_labels\n",
      "f.write(class_labels + \"\\n\")\n",
      "\n",
      "chunk_size = 1000\n",
      "num_test_samples = X_test_feats_consolidated.shape[0]\n",
      "\n",
      "for index_start in np.arange(0, num_test_samples, chunk_size):\n",
      "    y_test_prob = None\n",
      "    for model in best_softmax:\n",
      "        if y_test_prob is None:\n",
      "            y_test_prob = model.predict(X_test_feats_consolidated[index_start:np.minimum(index_start+chunk_size, num_test_samples)].T, \n",
      "                                  get_prob=True)\n",
      "        else:\n",
      "            current_test_prob = model.predict(X_test_feats_consolidated[index_start:np.minimum(index_start+chunk_size, num_test_samples)].T, \n",
      "                                  get_prob=True)\n",
      "            y_test_prob += current_test_prob\n",
      "    y_test_prob = y_test_prob.T\n",
      "   \n",
      "    for i in xrange(y_test_prob.shape[0]):\n",
      "        prob_string = [\"%.8f\" % number for number in y_test_prob[i]]\n",
      "        f.write(img_files[index_start + i] + \",\" + \",\".join(prob_string) + \"\\n\")\n",
      "    print \"Processed test images from {} to {}\".format(index_start,  min(index_start + chunk_size, num_test_samples))\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processed test images from 0 to 1000\n",
        "Processed test images from 1000 to 2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 2000 to 3000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 3000 to 4000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 4000 to 5000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 5000 to 6000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 6000 to 7000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 7000 to 8000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 8000 to 9000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 9000 to 10000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 10000 to 11000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 11000 to 12000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 12000 to 13000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 13000 to 14000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 14000 to 15000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 15000 to 16000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 16000 to 17000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 17000 to 18000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 18000 to 19000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 19000 to 20000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 20000 to 21000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 21000 to 22000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 22000 to 23000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 23000 to 24000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 24000 to 25000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 25000 to 26000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 26000 to 27000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 27000 to 28000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 28000 to 29000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 29000 to 30000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 30000 to 31000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 31000 to 32000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 32000 to 33000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 33000 to 34000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 34000 to 35000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 35000 to 36000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 36000 to 37000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 37000 to 38000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 38000 to 39000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 39000 to 40000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 40000 to 41000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 41000 to 42000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 42000 to 43000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 43000 to 44000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 44000 to 45000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 45000 to 46000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 46000 to 47000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 47000 to 48000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 48000 to 49000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 49000 to 50000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 50000 to 51000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 51000 to 52000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 52000 to 53000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 53000 to 54000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 54000 to 55000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 55000 to 56000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 56000 to 57000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 57000 to 58000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 58000 to 59000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 59000 to 60000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 60000 to 61000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 61000 to 62000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 62000 to 63000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 63000 to 64000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 64000 to 65000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 65000 to 66000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 66000 to 67000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 67000 to 68000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 68000 to 69000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 69000 to 70000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 70000 to 71000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 71000 to 72000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 72000 to 73000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 73000 to 74000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 74000 to 75000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 75000 to 76000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 76000 to 77000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 77000 to 78000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 78000 to 79000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 79000 to 80000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 80000 to 81000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 81000 to 82000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 82000 to 83000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 83000 to 84000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 84000 to 85000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 85000 to 86000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 86000 to 87000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 87000 to 88000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 88000 to 89000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 89000 to 90000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 90000 to 91000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 91000 to 92000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 92000 to 93000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 93000 to 94000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 94000 to 95000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 95000 to 96000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 96000 to 97000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 97000 to 98000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 98000 to 99000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 99000 to 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 100000 to 101000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 101000 to 102000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 102000 to 103000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 103000 to 104000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 104000 to 105000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 105000 to 106000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 106000 to 107000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 107000 to 108000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 108000 to 109000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 109000 to 110000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 110000 to 111000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 111000 to 112000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 112000 to 113000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 113000 to 114000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 114000 to 115000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 115000 to 116000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 116000 to 117000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 117000 to 118000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 118000 to 119000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 119000 to 120000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 120000 to 121000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 121000 to 122000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 122000 to 123000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 123000 to 124000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 124000 to 125000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 125000 to 126000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 126000 to 127000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 127000 to 128000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 128000 to 129000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 129000 to 130000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed test images from 130000 to 130400\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Try random forest on features got from best5 model\n",
      "import sklearn.ensemble as skle\n",
      "from skle import RandomForestClassifier\n",
      "clf = RandomForestClassifier(n_jobs=2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named sklearn.ensemble",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-123-c9c525cb8e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Try random forest on features got from best5 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mskle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named sklearn.ensemble"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}